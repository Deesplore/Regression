{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "MSa1f5Uengrz",
        "t6dVpIINYklI",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deesplore/Regression/blob/main/Bike_Sharing_Demand_Prediction_Regression_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    -  Bike Sharing Demand Prediction Regression project\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** - Prabhakar Subhash Harijan"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bikes are rented more when there is considerably low rainfall at 1.3mm bike count was 764 can say no rainfall... and count on that too is 739\n",
        "low it is around 12mm to 16mm between 11 to 1. \n",
        " Bikes are mostly renetd at 32* which is bascially a normal temeprature and has the highest no.. around 1692.. while the lowest at -15 around 25.  \n",
        "Highest number of bikes were rented during Summer seasons it was 1034 we can say that because many schools and colleges have there summer vacation leave, while least number of bikes were rented during Winter seasons. It was 225 and almost evenly in spring and autumn ranging from 730 to 8194.  \n",
        "Large no. of bikes are rented when there are non holiday it was 715 and very less no. is for holiday which was 499. Bikes are only rented only on functional day with the count of 729. Bikes rented on saturday was more it was around 719 while it was low on sundays around 667. Maximum no. of bike rented is in the evening at 6 pm which was 1502 and the least was in the morining at 4 am around 132. The above graph shows that bike should be more available in the evening as compared to morning. Customers have rented bikes more on friday following as considering weekends the count for friday was around 747 and it was some what same in the wednesday and monday to around 740 and 730 but the least no. of bike rented was on the Sunday 625.we can see that our bikes rented count went on increasing for the month is january from 201. it was in the peek in the month of june  which was 1245 and then it saw a sudden downfall around 249 counts in december.  \n",
        "\n",
        "Bikes should be more avaliable while there is less rainfall, bike should be more available in the range of 15* to  32* which is normal temperature so bikes should be more avaliable at that temperature ranges. Bikes should be available more on non holidays as compared to those on holiday. People prefer bikes more in the months of summer and almost equally in the spring and autumn and least in  winter,.. so bikes should be more available in summer season and accordingly in the following season. Bikes should be available almost on functional day and being on the safer end few counts for non functional day, bikes are mostly evenly rented ranging form 600 to 750 which is decent count so accordinly bike should be availabe everyday and count should be around 800 .. as better option, no. of supply of bike should me more in the month of june and gradually follows.\n",
        "\n",
        "Best performing model came out to be GradientBoostRegressor after doing the gridsearch. so we used it to final prediction.\n",
        "Important feature came out be hour, so bike should be available more duirng peak hours, which is in the evening.\n",
        "\n",
        "\n",
        "References:  \n",
        "\n",
        "Geekforgeeks.  \n",
        "\n",
        "Google.   \n",
        "\n",
        "Kaggle."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Deesplore"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes..**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importing required modules and loading dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime as dt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib.patheffects import PathPatchEffect, SimpleLineShadow, Normal\n",
        "import matplotlib.patheffects as path_effects\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from yellowbrick.regressor import ResidualsPlot\n",
        "from yellowbrick.regressor import PredictionError\n",
        "from yellowbrick.regressor import AlphaSelection\n",
        "from yellowbrick.regressor import CooksDistance\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "!pip install shap==0.40.0\n",
        "import shap \n",
        "import graphviz"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset=pd.read_csv(\"/content/drive/MyDrive/SeoulBikeData.csv\",encoding = 'unicode_escape')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 8760 rows and 14 columns"
      ],
      "metadata": {
        "id": "1TBCW_OJrQwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values in our dataset"
      ],
      "metadata": {
        "id": "iWCw2-2arbJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(dataset[dataset.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No duplicate values are found in our dataset"
      ],
      "metadata": {
        "id": "fOSb7av1rkVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.matrix(dataset)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.  We need to make the model in such a way that the supply of bikes are suficient for the customers.."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "dataset.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attribute Information:  \n",
        "**Date** : year-month-day  \n",
        "                       **Rented Bike count** - Count of bikes rented at each hour   \n",
        "                       **Hour** - Hour of the day  \n",
        "                       **Temperature**-Temperature in Celsius  \n",
        "                       **Humidity** - % Windspeed - m/s Visibility - 10m  \n",
        "                       **Dew point temperature** - Celsius   \n",
        "                       **Solar radiation** - MJ/m2   \n",
        "                       **Rainfall** - mm   \n",
        "                       **Snowfall** - cm   \n",
        "                       **Seasons** - Winter, Spring, Summer, Autumn   \n",
        "                       **Holiday** -   Holiday/No holiday   \n",
        "                       **Functioning Day** - Weekdays except official holidays\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "dataset.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",dataset[i].nunique(),\".\")\n",
        "\n",
        "unique_dataset = pd.DataFrame()\n",
        "unique_dataset['Features'] = dataset.columns\n",
        "unique=[]\n",
        "for i in dataset.columns:\n",
        "    unique.append(dataset[i].nunique())\n",
        "unique_dataset['Uniques'] = unique\n",
        "\n",
        "f, ax = plt.subplots(1,1, figsize=(15,7))\n",
        "\n",
        "splot = sns.barplot(x=unique_dataset['Features'], y=unique_dataset['Uniques'], alpha=0.8,color = 'red')\n",
        "for p in splot.patches:\n",
        "    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center',\n",
        "                   va = 'center', xytext = (0, 9), textcoords = 'offset points')\n",
        "plt.title('Bar plot for number of unique values in each column',weight='bold', size=15)\n",
        "plt.ylabel('#Unique values', size=12, weight='bold')\n",
        "plt.xlabel('Features', size=12, weight='bold')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mEPFlqQ7th9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Using Lambda function to strip date from string to Datetime format so to retrieve d,m,y\n",
        "dataset['Date'] = dataset['Date'].apply(lambda x:dt.strptime(x, \"%d/%m/%Y\"))\n",
        "dataset['Day'] = dataset['Date'].dt.day_name()\n",
        "dataset['Month'] = dataset['Date'].dt.month\n",
        "dataset['Year'] = dataset['Date'].dt.year"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Adding  a new column named Weekend with binary values, indicating 1 for weekend and 0 for a weekday.. \n",
        "dataset['weekend']=dataset['Day'].apply(lambda z: 1 if z=='Sunday' or  z=='Saturday' else 0)"
      ],
      "metadata": {
        "id": "cd23TZBGt-Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.drop(columns=['Date'],axis=1)\n",
        "dataset=dataset.drop(columns=['Year'],axis=1)"
      ],
      "metadata": {
        "id": "35zwiNvpuD_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1=dataset.copy()"
      ],
      "metadata": {
        "id": "7ENBHD5jUDex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.sample(5)"
      ],
      "metadata": {
        "id": "kzlnVdkDuscN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We first stripted our date columm is three parts for better understanding\n",
        "2. We added binary values and added a weekend column\n",
        "3. We drop date column after striping it.\n",
        "4. We Dropped year column as it was not necesaary."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "dataset.groupby('Month')['Rented Bike Count'].mean().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Visualisation of number of rented bikes vs Months:\n",
        "fig,ax=plt.subplots(figsize=(15,8))\n",
        "sns.barplot(data=dataset,x='Month',y='Rented Bike Count',path_effects=[path_effects.SimplePatchShadow(),path_effects.Normal()],color = 'lightblue' , ci=None)\n",
        "ax.set_title('Rented bikes  Vs Month ' , fontsize=18)\n",
        "ax.set_xlabel('Months',fontsize=15)\n",
        "ax.set_ylabel('Rented bikes count',fontsize=15)\n",
        "for bar in ax.patches:\n",
        "    ax.annotate(format(bar.get_height(), '.2f'),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=10, xytext=(0, 8),\n",
        "                   textcoords='offset points')"
      ],
      "metadata": {
        "id": "0UlHovtAvOwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.groupby('Month')['Rented Bike Count'].mean().sort_values(ascending=False).plot(kind='pie',shadow=True,autopct='%1.1f%%',colors = ( \"#ADD8E6\", \"yellow\"),figsize=(15,7),startangle=360,explode=[0.1,0.3,0.5,0.8,1.3,1.6,2,2.2,2.4,2.6,2.8,3])\n",
        "plt.axis('equal')\n",
        "plt.title('Rented bikes  Vs Month',fontsize = 10)"
      ],
      "metadata": {
        "id": "_MpFmWvYeRFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar graph is used to compare the items between different groups over time. Bar graphs are used to measure the changes over a period of time. When the changes are larger, a bar graph is the best option to represent the data. Thus i used it to find the relation between our bike rented w.r.t to months\n",
        "and i have use pie chart also just to visliuaize the detail more"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that our bikes rented count went on increasing for the month is january from 201. it was in the peek in the month of june which was 1245 and then it saw a sudden downfall around 249 counts in december"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After analyzing our above graph we can see that no. of supply of bike should me more in the month of june and gradually follows"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "dataset.groupby('Day')['Rented Bike Count'].mean().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of average number of rented bikes vs day:\n",
        " \n",
        "fig,ax=plt.subplots(figsize=(10,6))\n",
        "sns.barplot(data=dataset,x='Day',y='Rented Bike Count',path_effects=[path_effects.SimplePatchShadow(),path_effects.Normal()],ax=ax,ci=None , color ='Red')\n",
        "ax.set_title('Rented bikes Vs day ' , fontsize=18)\n",
        "ax.set_xlabel('Days',fontsize=15)\n",
        "for bar in ax.patches:\n",
        "    ax.annotate(format(bar.get_height(), '.2f'),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=10, xytext=(0, 8),\n",
        "                   textcoords='offset points')\n",
        "ax.set_ylabel('Rented Bikes per day',fontsize=15)"
      ],
      "metadata": {
        "id": "e6BdrBp9v5MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pointplot(data=dataset,x='Day',y='Rented Bike Count',dodge=True)\n",
        "plt.grid(True)   "
      ],
      "metadata": {
        "id": "OY5aKeGSfh_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar graph is used to compare the items between different groups over time. Bar graphs are used to measure the changes over a period of time. When the changes are larger, a bar graph is the best option to represent the data.\n",
        "Thus i used this graph to know how much bike is rented each day, And we have used pointplot to just to analyze our relation more clearly."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customers have rented bikes more on friday following as considering weekends the count for friday was around 747 and it was some what same in the wednesday and monday to around 740 and 730 but the least no. of bike rented was on the Sunday 625.."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing the above graph concludes that bikes are mostly evenly rented ranging form 600 to 750 which is desent count so accordinly bike should be availabe everyday and count should be around 800 .. as better option."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "dataset.groupby('Hour')['Rented Bike Count'].mean().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of Rented bikes vs Hour of the Day:\n",
        "fig,ax=plt.subplots(figsize=(20,10))\n",
        "sns.boxplot(data=dataset,x='Hour',y='Rented Bike Count', color ='blue')\n",
        "ax.set_title('Rented Bikes by day Vs Hour ', fontsize=18)\n",
        "ax.set_xlabel('Hour',fontsize=15)\n",
        "ax.set_ylabel('Rented Bikes',fontsize=15)"
      ],
      "metadata": {
        "id": "bJyQAK_Uw6rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(20,6))\n",
        "sns.barplot(data=dataset,x='Hour',y='Rented Bike Count',path_effects=[path_effects.SimplePatchShadow(),path_effects.Normal()],ax=ax,ci=None , color ='black')\n",
        "ax.set_title('Rented bikes Vs hour ' , fontsize=18)\n",
        "ax.set_xlabel('Days',fontsize=15)\n",
        "for bar in ax.patches:\n",
        "    ax.annotate(format(bar.get_height(), '.2f'),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=10, xytext=(0, 8),\n",
        "                   textcoords='offset points')\n",
        "ax.set_ylabel('Rented Bikes per hour',fontsize=15)"
      ],
      "metadata": {
        "id": "jMznA0q0gmaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box plots are used to show distributions of numeric data values, especially when you want to compare them between multiple groups. They are built to provide high-level information at a glance, offering general information about a group of data's symmetry, skew, variance, and outliers.\n",
        "Thus i used to find the tendency of bike rented by hour w.r.t to day,\n",
        "Barplot is used to get clear insights of the data."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximum no. of bike rented is in the evening at 6 pm which was 1502 and the least was in the morining at 4 am around 132. The above graph shows that bike should be more available in the evening as compared to morning."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bikes should be more availbale in the evening and evenely distributed from the morning and afternoon too.. "
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "dataset.groupby('weekend')['Rented Bike Count'].mean().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of Rented bikes vs Hour of the Day:\n",
        "fig,ax=plt.subplots(figsize=(20,10))\n",
        "sns.pointplot(data=dataset,x='weekend',y='Rented Bike Count',  color ='green')\n",
        "ax.set_title('Rented Bikes by day Vs weekend ', fontsize=18)\n",
        "ax.set_xlabel('weekend',fontsize=15)\n",
        "ax.set_ylabel('Rented Bikes',fontsize=15)"
      ],
      "metadata": {
        "id": "aPnBOMMYxg01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.groupby('weekend')['Rented Bike Count'].mean().sort_values(ascending=False).plot(kind='pie',shadow=True,autopct='%1.1f%%',colors = ('#F0FFFF','#98F5FF'),figsize=(15,7),explode=[0,0.05])\n",
        "plt.title('Rented Bikes by day Vs weekend ', fontsize=18)"
      ],
      "metadata": {
        "id": "RzMRXHfthHQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I have used pie chart to the percentage count.\n",
        "A point plot uses scatter plot glyphs to visualize features like point estimates and confidence intervals. A point plot uses scatter plot points to represent the central tendency of numeric data.These plots make use of error bars to indicate any uncertainty around the numeric variables\n",
        "Thus i used it to find the tendency of bike rented by hour on weekend."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bikes rented on saturday was more it was around 719 while it was low on sundays \n",
        "around 667"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can say people rented bikes more on saturday while less on sundays so the availabiality of the bikes should be more on saturday"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "dataset.groupby('Functioning Day')['Rented Bike Count'].mean().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of rented Bikes Vs Functioning Day:\n",
        "\n",
        "fig,ax=plt.subplots(figsize=(6,8))\n",
        "sns.barplot(data=dataset,x='Functioning Day',y='Rented Bike Count',path_effects=[path_effects.SimplePatchShadow(),path_effects.Normal()], ci=None,color = 'yellow' )\n",
        "for bar in ax.patches:\n",
        "    ax.annotate(format(bar.get_height(), '.2f'),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=15, xytext=(0, 8),\n",
        "                   textcoords='offset points')\n",
        "ax.set_title('Rented bikes Vs Functioning Day ', fontsize=18)\n",
        "ax.set_xlabel('Functioning Day',fontsize=15)\n",
        "ax.set_ylabel('Rented Bikes',fontsize=15)"
      ],
      "metadata": {
        "id": "_z78Wg8i2qOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar graph is used to compare the items between different groups over time. Bar graphs are used to measure the changes over a period of time. When the changes are larger, a bar graph is the best option to represent the data.\n",
        "Thus i used this graph to get a clear look of bike rented on functional day"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bikes are only rented only on functional day. with the count of 729"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bikes should be available almost on functional day and being on the safer end few counts for non functional day."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of Rented Bikes Vs Holiday or not:\n",
        "\n",
        "fig,ax=plt.subplots(figsize=(10,7))\n",
        "sns.barplot(data=dataset,x='Holiday',y='Rented Bike Count',path_effects=[path_effects.SimplePatchShadow(),path_effects.Normal()] ,color ='orange', ci= None)\n",
        "for bar in ax.patches:\n",
        "    ax.annotate(format(bar.get_height(), '.2f'),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=13, xytext=(0, 8),\n",
        "                   textcoords='offset points')\n",
        "ax.set_title('Rented bikes Vs Holiday ' , fontsize=18)\n",
        "ax.set_xlabel('Holiday',fontsize=15);\n",
        "ax.set_ylabel('Rented Bikes',fontsize=15)"
      ],
      "metadata": {
        "id": "d1MiaP6K3IW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar graph is used to compare the items between different groups over time. Bar graphs are used to measure the changes over a period of time. When the changes are larger, a bar graph is the best option to represent the data.\n",
        "Thus i used this graph to get a clear look of bike rented on holidays"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Large no. of bikes are rented when there are non holiday it was 715 and very less no. is for holiday which was 499."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BIkes should be available more on non holidays as compared to those on holiday.."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "k=pd.DataFrame(dataset.groupby('Seasons')['Rented Bike Count'].mean().sort_values(ascending=False))\n",
        "k.head()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of Rented Bikes Vs Seasons:\n",
        "fig,ax=plt.subplots(figsize=(10,7))\n",
        "sns.pointplot(data=dataset,x='Seasons',y='Rented Bike Count', color ='pink' )\n",
        "ax.set_title('Rented bikes Vs Seasons ' , fontsize=18)\n",
        "ax.set_xlabel('Seasons',fontsize=15)\n",
        "ax.set_ylabel('Rented Bikes',fontsize=15)"
      ],
      "metadata": {
        "id": "978NQdIQ3puw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.groupby('Seasons')['Rented Bike Count'].mean().sort_values(ascending=False).plot(kind='pie',shadow=True,autopct='%1.1f%%',colors = ('#F0FFFF','#98F5FF'),figsize=(15,7),explode=[0,0.05,0.1,0.15])\n",
        "plt.title('Rented bikes Vs Seasons', fontsize=18)"
      ],
      "metadata": {
        "id": "pQYetgOuhzky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A point plot uses scatter plot glyphs to visualize features like point estimates and confidence intervals. A point plot uses scatter plot points to represent the central tendency of numeric data.These plots make use of error bars to indicate any uncertainty around the numeric variables\n",
        "Thus i used it to find the tendency of bike rented accoring to seasons,I have use pie chart also to know the percentage count of the data also."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that Highest number of bikes were rented during *Summer seasons* it was 1034 while least number of bikes were rented during *Winter seasons*. it was 225 and almost evenly in spring and autumn\n",
        "ranging from 730 to 819"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "People prefer bikes more in the months of summer and almost equally in the spring and autumn and least in  winter,.. so bikes should be more available in summer season and accordingly in the following season."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "k=pd.DataFrame(dataset.groupby('Temperature(°C)')['Rented Bike Count'].mean().sort_values(ascending=False))\n",
        "k.head(5)"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.tail(5)"
      ],
      "metadata": {
        "id": "SjQrzva34Olh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_bike=k.groupby('Temperature(°C)')['Rented Bike Count'].mean()\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "plt.xlabel('Temperature(°C)')\n",
        "plt.ylabel('Rented Bike Count')\n",
        "sns.scatterplot(data=k,x='Temperature(°C)',y='Rented Bike Count', color ='black', )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FN5jrRmz4I_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scatter plots’ primary uses are to observe and show relationships between two numeric variables. The dots in a scatter plot not only report the values of individual data points, but also patterns when the data are taken as a whole.\n",
        "so by using the graph we can see the tendency of temperature how much it is affecting our renetd bike count "
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bikes are mostly renetd at 32* which is bascially a normal temeprature and has the highest no.. around 1692.. while the lowest at -15 around 25"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes graph tell us that bike should be more available in the range of 15* to  32* which is normal temperature so bikes should be more avaliable at that temperature ranges."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "avg_bike=pd.DataFrame(dataset.groupby('Rainfall(mm)')['Rented Bike Count'].mean().sort_values(ascending=False))\n",
        "avg_bike.head(5)"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_bike.tail(5)"
      ],
      "metadata": {
        "id": "uLQdso5A4uk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of Average Bike rented during rainfall:\n",
        "\n",
        "avg_bike=dataset.groupby('Rainfall(mm)')['Rented Bike Count'].mean()\n",
        "plt.figure(figsize=(22,7))\n",
        "ax=avg_bike.plot(legend=True,title=f'Average Bike rented during rainfall',color='blue',kind='bar',path_effects=[path_effects.SimplePatchShadow(),path_effects.Normal()])\n",
        "for bar in ax.patches:\n",
        "    ax.annotate(format(bar.get_height(), '.2f'),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=7, xytext=(0, 8),\n",
        "                   textcoords='offset points')\n",
        "ax.set_xticks(range(len(avg_bike)))\n",
        "ax.set_xticklabels(avg_bike.index.tolist(),rotation = 90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lL9kccKq4wlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar graph is used to compare the items between different groups over time. Bar graphs are used to measure the changes over a period of time. When the changes are larger, a bar graph is the best option to represent the data.\n",
        "Thus i used this graph to get a clear look of bike rented during rainfall"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bikes are rented more when there is considerably low rainfall at 1.3mm bike counted was 764 can say no rainfall... and count on that too is 739\n",
        "low is around 12mm to 16mm between 11 to 13 "
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bikes should be more avaliable while there is less rainfall."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "corr = dataset.corr()\n",
        "corr.style.background_gradient(cmap='ocean_r')"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. A correlation matrix is used to summarize data, as an input into a more advanced analysis, and as a diagnostic for advanced analyses. The range of correlation is [-1,1].\n",
        "\n",
        "Thus to know the correlation between all the variables along with the correlation coeficients, i used correlation heatmap."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature and Dew point temperature has highest correlation with a value nearly to 1 . it was (0.912798)\n",
        "Rest all correlation can be depicted from the above chart."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Pair Plot "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(dataset, hue=\"Rented Bike Count\")"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Seaborn Pairplot allows us to plot pairwise relationships between variables within a dataset. This creates a nice visualisation and helps us understand the data by summarising a large amount of data in a single figure."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rented Bike Count is more affected by heavy rainfall, snowfall.There is low count on weekends too.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Does Humidity affect the Count of Bikes to be rented?  \n",
        "2. Is there any relation between Visibility and Rented Bike Count?   \n",
        "3. Is there any realtion between rainfall and rented bike count?"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does Humidity affect the Count of Bikes to be rented?"
      ],
      "metadata": {
        "id": "3FGMVG5JT0UH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H0:Number of bikes are not affected by Humidity \n",
        "\n",
        "H1:Number of bikes are  affected by Humidity"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "\n",
        "# Extract the two columns of interest\n",
        "column1 = dataset1['Rented Bike Count']\n",
        "column2 = dataset1['Humidity(%)']\n",
        "\n",
        "# Conduct a two-sample t-test\n",
        "t_stat, p_val = ttest_ind(column1, column2)\n",
        "\n",
        "# Print the results\n",
        "print(\"T-statistic: \", t_stat)\n",
        "print(\"P-value: \", p_val)"
      ],
      "metadata": {
        "id": "WrGTMOc5Is0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we accept our alternate hypothersis  \n",
        "I.e No. of  Rented Bike Counts are affected by Humidity\n"
      ],
      "metadata": {
        "id": "s2-rrWH4L-uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used two tailed t-test to obtain the value"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A two-tailed test is appropriate if you want to determine if there is any difference between the groups you are comparing"
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is there any relation between Visibility and Rented Bike Count? "
      ],
      "metadata": {
        "id": "jJviVL7IUN1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H0:There is no relationship betwen Rented BIke Count and Visibility  \n",
        "H1:There is relationship betwen Rented BIke Count and Visibility"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Create two arrays of data\n",
        "x = dataset1['Rented Bike Count']\n",
        "y = dataset1['Visibility (10m)']\n",
        "\n",
        "# Calculate the Pearson correlation coefficient and p-value\n",
        "corr_coef, p_value = stats.pearsonr(x, y)\n",
        "\n",
        "# Print the results\n",
        "print('Pearson correlation coefficient:', corr_coef)\n",
        "print('P-value:', p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our p value is belows 0.05 so we accept the alternate hypothesis\n"
      ],
      "metadata": {
        "id": "tSLzu6WfLKhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson correlation test is used by me"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The significance of PCC is basically to show you how strongly correlated the two variables/lists are"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is there any realtion between rainfall and rented bike count?"
      ],
      "metadata": {
        "id": "O_Xenf6KUcrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H0:There is relationship between Rented bike count and the rainfall  \n",
        "H1:There is no relationship between Rented bike count and the rainfall  "
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Create a contingency table\n",
        "cont_table = pd.crosstab(dataset1['Rented Bike Count'], dataset['Rainfall(mm)'])\n",
        "\n",
        "# Conduct chi-square test\n",
        "chi2_stat, p_val, dof, exp_freq = stats.chi2_contingency(cont_table)\n",
        "\n",
        "# Print results\n",
        "print(\"Chi-square statistic:\", chi2_stat)\n",
        "print(\"p-value:\", p_val)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we accept our null hypothesis"
      ],
      "metadata": {
        "id": "oyG3OKvErueG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used chi-square test here"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " chi-square test is a statistical test used to compare observed results with expected results. The purpose of this test is to determine if a difference between observed data and expected data is due to chance, or if it is due to a relationship between the variables you are studying"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There were no missing values present in the data"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.sample(5)"
      ],
      "metadata": {
        "id": "kOIS9t_kHwdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_vars = ['Rented Bike Count', 'Hour', 'Temperature(°C)', 'Humidity(%)',\n",
        "       'Wind speed (m/s)', 'Visibility (10m)', 'Dew point temperature(°C)',\n",
        "       'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)']\n",
        "Categorical_vars = ['Seasons',\n",
        "       'Holiday', 'Functioning Day', 'Day']"
      ],
      "metadata": {
        "id": "EHzdAbACr5IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total outliers for each column\n",
        "Q1 = dataset[numerical_vars].quantile(0.25)\n",
        "Q3 = dataset[numerical_vars].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "((dataset[numerical_vars] < (Q1 - 1.5 * IQR)) | (dataset[numerical_vars] > (Q3 + 1.5 * IQR))).sum()"
      ],
      "metadata": {
        "id": "JM1pHpYkr_LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "sns.boxplot(data=dataset)\n",
        "plt.xticks(rotation = 90)"
      ],
      "metadata": {
        "id": "U0kL8_CvBEgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(dataset['Rented Bike Count'],palette=\"mako\")"
      ],
      "metadata": {
        "id": "T5Bb4m66sJVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the IQR\n",
        "percentile25 =dataset['Rented Bike Count'].quantile(0.25)\n",
        "percentile75 =dataset['Rented Bike Count'].quantile(0.75)"
      ],
      "metadata": {
        "id": "trg57XsyveO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q75, q25 = np.percentile(dataset['Rented Bike Count'],[75 ,25])\n",
        "iqr = q75 - q25\n"
      ],
      "metadata": {
        "id": "9QYsXvMoIHbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the upper and lower limits\n",
        "upper_limit = percentile75 + 1.5 * iqr\n",
        "lower_limit = percentile25 - 1.5 * iqr"
      ],
      "metadata": {
        "id": "biiHsA5ntU12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trimming outlier\n",
        "new_df = dataset[dataset['Rented Bike Count'] < upper_limit]\n",
        "new_df.shape"
      ],
      "metadata": {
        "id": "-SB6vofHxHD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the plots after trimming \n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(2,2,1)\n",
        "sns.distplot(dataset['Rented Bike Count'])\n",
        "plt.subplot(2,2,2)\n",
        "sns.boxplot(dataset['Rented Bike Count'])\n",
        "plt.subplot(2,2,3)\n",
        "sns.distplot(new_df['Rented Bike Count'])\n",
        "plt.subplot(2,2,4)\n",
        "sns.boxplot(new_df['Rented Bike Count'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jSFlurLjxSSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capping\n",
        "new_df_cap = dataset.copy()\n",
        "new_df_cap['Rented Bike Count'] = np.where(new_df_cap['Rented Bike Count'] > upper_limit,upper_limit,\n",
        "    np.where(new_df_cap['Rented Bike Count'] < lower_limit,lower_limit,new_df_cap['Rented Bike Count']))"
      ],
      "metadata": {
        "id": "Zi4ue79ixmn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the plots after capping\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.subplot(2,2,1)\n",
        "sns.distplot(dataset['Rented Bike Count'])\n",
        "plt.subplot(2,2,2)\n",
        "sns.boxplot(dataset['Rented Bike Count'])\n",
        "plt.subplot(2,2,3)\n",
        "sns.distplot(new_df_cap['Rented Bike Count'])\n",
        "plt.subplot(2,2,4)\n",
        "sns.boxplot(new_df_cap['Rented Bike Count'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XRYW24uryraz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(dataset['Wind speed (m/s)'],palette='rocket')"
      ],
      "metadata": {
        "id": "uGjsjTBLzWVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iqr1=  dataset['Wind speed (m/s)'].quantile(0.75)-dataset['Wind speed (m/s)'].quantile(0.25)\n",
        "dataset['Wind speed (m/s)']= dataset['Wind speed (m/s)'].mask(dataset['Wind speed (m/s)']>(dataset['Wind speed (m/s)'].quantile(0.75)+1.5*data_iqr1), dataset['Wind speed (m/s)'].mean())\n"
      ],
      "metadata": {
        "id": "Z-mGMMED1nxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(dataset['Wind speed (m/s)'],palette='viridis')"
      ],
      "metadata": {
        "id": "noUIoW841uma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(dataset['Solar Radiation (MJ/m2)'],palette='magma')"
      ],
      "metadata": {
        "id": "BOhcmFTA1qS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iqr1=  dataset['Solar Radiation (MJ/m2)'].quantile(0.75)-dataset['Solar Radiation (MJ/m2)'].quantile(0.25)\n",
        "dataset['Solar Radiation (MJ/m2)']= dataset['Solar Radiation (MJ/m2)'].mask(dataset['Solar Radiation (MJ/m2)']>(dataset['Solar Radiation (MJ/m2)'].quantile(0.75)+1.5*data_iqr1), dataset['Solar Radiation (MJ/m2)'].mean())"
      ],
      "metadata": {
        "id": "8S0-9DO5ZiTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(dataset['Rainfall(mm)'],palette='flare')"
      ],
      "metadata": {
        "id": "8x-RqyVO15Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iqr1=  dataset['Rainfall(mm)'].quantile(0.75)-dataset['Rainfall(mm)'].quantile(0.25)\n",
        "dataset['Rainfall(mm)']= dataset['Rainfall(mm)'].mask(dataset['Rainfall(mm)']>(dataset['Rainfall(mm)'].quantile(0.75)+1.5*data_iqr1), dataset['Rainfall(mm)'].mean())"
      ],
      "metadata": {
        "id": "ckavbMJP1-Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(dataset['Rainfall(mm)'])"
      ],
      "metadata": {
        "id": "RTNl6t6b17Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(dataset['Snowfall (cm)'])"
      ],
      "metadata": {
        "id": "JTwgcNA_2aGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iqr1=  dataset['Snowfall (cm)'].quantile(0.75)-dataset['Snowfall (cm)'].quantile(0.25)\n",
        "dataset['Snowfall (cm)']= dataset['Snowfall (cm)'].mask(dataset['Snowfall (cm)']>(dataset['Rainfall(mm)'].quantile(0.75)+1.5*data_iqr1), dataset['Snowfall (cm)'].mean())"
      ],
      "metadata": {
        "id": "ZWsH9xOR2oBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(dataset['Snowfall (cm)'])"
      ],
      "metadata": {
        "id": "e09Vd_JQ2a7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used the IQR method of identifying outliers to set up a “fence” outside of Q1 and Q3. Any values that fall outside of this fence are considered outliers. To build this fence we take 1.5 times the IQR and then subtract this value from Q1 and add this value to Q3. This gives us the minimum and maximum fence posts that we compare each observation to. Any observations that are more than 1.5 IQR below Q1 or more than 1.5 IQR above Q3 are considered outliers.\n",
        "and after our rented bike count columns we just inputed the outliers with mean\n"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "enc = OrdinalEncoder()"
      ],
      "metadata": {
        "id": "6kbkFuY4RUAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.sample(5)"
      ],
      "metadata": {
        "id": "8DuHueKOWHNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "dataset['Functioning Day']=dataset['Functioning Day'].map({'Yes':1,'No':0})\n",
        "dataset['Holiday']=dataset['Holiday'].map({'No Holiday':0,'Holiday':1})\n",
        "dataset['Seasons']=dataset['Seasons'].map({'Summer':0,'Spring':1,'Winter':2,'Autumn':3})\n",
        "dataset['Day']=dataset['Day'].map({'Sunday':0,'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6})"
      ],
      "metadata": {
        "id": "C9mtjyuxST0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.sample(5)"
      ],
      "metadata": {
        "id": "1s6rEJLPSBDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we did ordinal encoding because,This type of encoding is used when the variables in the data are ordinal, ordinal encoding converts each label into integer values and the encoded data represents the sequence of labels."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we created new feature as weekend to understand the distribution of count between weekdays and weekends and we did the eda for better visualization."
      ],
      "metadata": {
        "id": "x1gVVWnmfm3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "corr = dataset.corr()\n",
        "corr.style.background_gradient(cmap='ocean')"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definig function for VIF:\n",
        "\n",
        "def calc_vif(X):\n",
        " \n",
        "   # Calculating VIF:\n",
        "   \n",
        "   vif = pd.DataFrame()\n",
        "   vif[\"variables\"] = X.columns\n",
        "   vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        " \n",
        "   return(vif)"
      ],
      "metadata": {
        "id": "kL-U0hz35pP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(dataset[[i for i in dataset.describe().columns]])"
      ],
      "metadata": {
        "id": "C_7uZr_V5tYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(dataset[[i for i in dataset.describe().columns if i not in ['Rented Bike Count','Temperature(°C)','Functioning Day']]])"
      ],
      "metadata": {
        "id": "_XCZ-SbQ50eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.drop(columns=['Temperature(°C)','Functioning Day'],axis=1)"
      ],
      "metadata": {
        "id": "lozaBetU6afR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining function for feature importance:\n",
        "def get_feat_imp(model):\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "  plt.figure(figsize=(15,8))\n",
        "  plt.title('Feature Importance')\n",
        "  feat_importances.nlargest(10).plot(kind='bar', color= 'red',path_effects=[path_effects.SimplePatchShadow(),path_effects.Normal()])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "DKAjBFZb6p5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First I checked the corrleation map of our dataset to see which of the features are correlated... then i used Vif as we known  \n",
        "A variance inflation factor (VIF) is a measure of the amount of multicollinearity in regression analysis. Multicollinearity exists when there is a correlation between multiple independent variables in a multiple regression model. This can adversely affect the regression results. Thus, the variance inflation factor can estimate how much the variance of a regression coefficient is inflated due to multicollinearity."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here i found features...such as  \n",
        " \n",
        "1 Hour  \n",
        "\n",
        "2\tHumidity(%)  \n",
        "\n",
        "3\tWind speed (m/s)  \n",
        "\n",
        "4\tVisibility (10m)  \n",
        "\n",
        "5\tDew point temperature(°C)  \n",
        "\n",
        "6\tSolar Radiation (MJ/m2)  \n",
        "\n",
        "7\tRainfall(mm)  \n",
        "\n",
        "8\tSnowfall (cm)  \n",
        "\n",
        "9\tHoliday  \n",
        "\n",
        "10 Month    \n",
        "\n",
        "11 weekend  \n",
        "\n",
        "12 Day  \n",
        "\n",
        "13 Seasons  \n",
        "\n",
        "as there vif value is less than 10 and they are less correlated..."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "for col in dataset:\n",
        "  plt.figure(figsize=(10,6))\n",
        "  sns.displot(x=dataset[col] , color ='green')\n",
        "  plt.xlabel(col)\n",
        "  plt.axvline(dataset[col].mean(),color='magenta', linestyle='dashed',linewidth=2)\n",
        "  plt.axvline(dataset[col].median(),color='cyan', linestyle='dashed',linewidth=2)\n",
        "  plt.show()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Rented Bike Count']=np.sqrt(dataset['Rented Bike Count'])"
      ],
      "metadata": {
        "id": "R4Ojdbpu_FQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.skew())"
      ],
      "metadata": {
        "id": "OZiaVMrH5Low"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.kurt())"
      ],
      "metadata": {
        "id": "cBFps0ML6lyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.hist('Rented Bike Count',figsize=(10,8))\n",
        "plt.title('density vs Rented Bike Count')\n",
        "plt.axvline(dataset['Rented Bike Count'].mean(),color='magenta', linestyle='dashed',linewidth=2)\n",
        "plt.axvline(dataset['Rented Bike Count'].median(),color='cyan', linestyle='dashed',linewidth=2)\n",
        "plt.ylabel('density')\n",
        "plt.xlabel('Rented Bike Count')"
      ],
      "metadata": {
        "id": "jn8mqHkVBUFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accordingly our target column is rented bike count so we did the required  square root transformation...."
      ],
      "metadata": {
        "id": "Gejryq_jBtVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from numpy import asarray\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(dataset)\n",
        "print(scaled)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating copy of data:\n",
        "\n",
        "data_ml= dataset.copy()\n",
        "\n",
        "# Creating the data of dependent and independent variables:\n",
        "\n",
        "y = data_ml['Rented Bike Count']\n",
        "X = data_ml.drop(columns=['Rented Bike Count'], axis=1)"
      ],
      "metadata": {
        "id": "8ssPjE7qCJuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "ZBVaT0PGK0_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the target value is a good idea in regression modelling; scaling of the data makes it easy for a model to learn and understand the problem. Scaling of the data comes under the set of steps of data pre-processing when we are performing machine learning algorithms in the data set.  \n",
        "I have used Minmaxscaler technique here as we know MinMaxScaler is used when the upper and lower boundaries are well known from domain knowledge. MinMaxScaler scales all the data features in the range [0, 1] or else in the range [-1, 1] if there are negative values in the dataset. This scaling compresses all the inliers in the narrow range."
      ],
      "metadata": {
        "id": "oDbYLFg9SG0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No it is not required"
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function for plotting y test  and y train values:\n",
        "def get_linear_graph(pred_value, y_test ):\n",
        "  plt.figure(figsize=(15,7))\n",
        "  plt.plot(pred_value[:100])\n",
        "  plt.plot(np.array(y_test[:100]))\n",
        "  plt.legend(['Predicted','Actual'])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "JCT9ULYwCaA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I Have used splitting ratio of 80:20 as it is consider to be the best ratio for model training i.e 80% for trainig and 20% for testing."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No the data is not imbalanced"
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 - Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting onto Linear regression Model:\n",
        "\n",
        "reg= LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# Getting the X_train and X-test value:\n",
        "y_pred_train=reg.predict(X_train)\n",
        "y_pred_test=reg.predict(X_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "eYkFBS54Cx2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "vwa_2n8VIjkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_linear_graph(y_pred_test,y_pred_train)"
      ],
      "metadata": {
        "id": "zCzxUR2xIwnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Calculate MSE, MAE, R2 for training data:\n",
        "MSEl = mean_squared_error((y_train), (y_pred_train))\n",
        "MAEl= mean_absolute_error(y_train, y_pred_train)\n",
        "r2l = r2_score(y_train, y_pred_train)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for testing data:\n",
        "MSEtestl = mean_squared_error((y_test), (y_pred_test))\n",
        "MAEtestl= mean_absolute_error(y_test, y_pred_test)\n",
        "r2testl = r2_score(y_test, y_pred_test)\n",
        "# Printing Errors:"
      ],
      "metadata": {
        "id": "WqmkB-f5nKZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Errors:\n",
        "\n",
        "print('Training Errors\\nMSE:', MSEl , '\\nMAE:' , MAEl , '\\nR2:',round((r2l),3))\n",
        "print('\\n\\nTesting Errors\\nMSE:', MSEtestl , '\\nMAE:' , MAEtestl , '\\nR2:',round((r2testl),3))"
      ],
      "metadata": {
        "id": "1Cr571o_nMwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz = ResidualsPlot(LinearRegression(),\n",
        "                    train_color=\"dodgerblue\",\n",
        "                    test_color=\"tomato\",\n",
        "                    fig=plt.figure(figsize=(9,6))\n",
        "                    )\n",
        "\n",
        "viz.fit(X_train, y_train)\n",
        "viz.score(X_test, y_test)\n",
        "viz.show()"
      ],
      "metadata": {
        "id": "Yib_1s4lX_Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz = PredictionError(LinearRegression(),\n",
        "                      fig=plt.figure(figsize=(6,6))\n",
        "                      )\n",
        "\n",
        "viz.fit(X_train, y_train)\n",
        "viz.score(X_test, y_test)\n",
        "viz.show()"
      ],
      "metadata": {
        "id": "3OhHrFI4Xt5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict1={'Model':'Linear regression ',\n",
        "       'MAE':round((MAEl),3),\n",
        "       'MSE':round((MSEl),3),\n",
        "       'R2_score':round((r2l),3),\n",
        "       }\n",
        "training_df=pd.DataFrame(dict1,index=[1])"
      ],
      "metadata": {
        "id": "d3CpcsVvKLS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison:\n",
        "dict2={'Model':'Linear regression ',\n",
        "       'MAE':round((MAEtestl),3),\n",
        "       'MSE':round((MSEtestl),3),\n",
        "       'R2_score':round((r2testl),3)\n",
        "       }\n",
        "test_df=pd.DataFrame(dict2,index=[1])"
      ],
      "metadata": {
        "id": "Tw9DY9s3KOXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We haven't done hyperparameter tuning for this model as we know LinearRegression does not have hyperparameters that can be tuned."
      ],
      "metadata": {
        "id": "23-15PwETnZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 - Polynomial Regression"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "# Fitting training data onto Polynomial regression Model :\n",
        "poly_reg = PolynomialFeatures(degree = 2)\n",
        "\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "\n",
        "X_poly_test = poly_reg.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting training data onto Polynomial regression Model :\n",
        "poly_reg = PolynomialFeatures(degree = 2)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "X_poly_test = poly_reg.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "iXbXzpcJKjAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting training data onto Polynomial regression Model:\n",
        "poly = LinearRegression().fit(X_poly, y_train)"
      ],
      "metadata": {
        "id": "gxUr_MsiKn6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_poly"
      ],
      "metadata": {
        "id": "yMzlR9n-LCep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_poly_test"
      ],
      "metadata": {
        "id": "EgITa61LMpjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Getting the y_train and y-test value:\n",
        "y_pred_poly_train = poly.predict(X_poly)\n",
        "y_pred_poly_test= poly.predict(X_poly_test)"
      ],
      "metadata": {
        "id": "Uyekw7obKuhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_linear_graph(y_pred_poly_test , y_test )"
      ],
      "metadata": {
        "id": "echOPWOvK5Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for training data:\n",
        "MSEp = mean_squared_error((y_train), (y_pred_poly_train))\n",
        "MAEp= mean_absolute_error(y_train, y_pred_poly_train)\n",
        "r2p = r2_score(y_train, y_pred_poly_train)"
      ],
      "metadata": {
        "id": "sgR6VVJpLBwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for testing data:\n",
        "MSEtestp = mean_squared_error((y_test), (y_pred_poly_test))\n",
        "MAEtestp= mean_absolute_error(y_test, y_pred_poly_test)\n",
        "r2testp = r2_score(y_test, y_pred_poly_test)"
      ],
      "metadata": {
        "id": "40AI3atXLDg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Errors:\n",
        "print('Training Errors\\nMSE:', MSEp , '\\nMAE:' , MAEp , '\\nR2:',round((r2p),2))\n",
        "print('\\n\\nTesting Errors\\nMSE:', MSEtestp , '\\nMAE:' , MAEtestp , '\\nR2:',round((r2testp),2))"
      ],
      "metadata": {
        "id": "n4jkhT6YLESZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "dict1={'Model':'Polynomial regression ',\n",
        "       'MAE':round((MAEp),3),\n",
        "       'MSE':round((MSEp),3),\n",
        "       'R2_score':round((r2p),3)\n",
        "       }\n",
        "training_df=training_df.append(dict1,ignore_index=True)\n",
        "# storing the test set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict2={'Model':'Polynomial regression ',\n",
        "       'MAE':round((MAEtestp),3),\n",
        "       'MSE':round((MSEtestp),3),\n",
        "       'R2_score':round((r2testp),3)\n",
        "       }\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "QkcO_MpoLKhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We didn't perfrom hyperparameter tuning for this model."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT has shown slight improvement in the model as compared to above linear regression model."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 -- Decision Tree and Random Forest"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "# Creating object wth Decision tree regressor with critera of mean squared error, maximum depth being 10, maximum leaf noodes being 120:\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "decision_regressor = DecisionTreeRegressor(criterion='squared_error', max_depth=10, max_leaf_nodes=120)\n",
        "decision_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the y_train and y-test value:\n",
        "y_pred_train_d = decision_regressor.predict(X_train)\n",
        "y_pred_test_d = decision_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "wTAfW6OBLTCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_linear_graph(y_pred_test_d , y_test )"
      ],
      "metadata": {
        "id": "wkYDmgFsLaZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for training data:\n",
        "MSEdt = mean_squared_error((y_train), (y_pred_train_d))\n",
        "MAEdt = mean_absolute_error(y_train, y_pred_train_d)\n",
        "r2dt = r2_score(y_train, y_pred_train_d)"
      ],
      "metadata": {
        "id": "mZzoS6y3LVjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for testing data:\n",
        "MSEtestdt = mean_squared_error((y_test), (y_pred_test_d))\n",
        "MAEtestdt = mean_absolute_error(y_test, y_pred_test_d)\n",
        "r2testdt = r2_score(y_test, y_pred_test_d)"
      ],
      "metadata": {
        "id": "Bom-pRr4LXgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Errors:\n",
        "print('Training Errors\\nMSE:', MSEdt , '\\nMAE:' , MAEdt , '\\nR2:',round((r2dt),3))\n",
        "print('\\n\\nTesting Errors\\nMSE:', MSEtestdt , '\\nMAE:' , MAEtestdt , '\\nR2:',round((r2testdt),3))"
      ],
      "metadata": {
        "id": "oRtru9k5Lcq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz = ResidualsPlot(DecisionTreeRegressor(criterion='squared_error', max_depth=10, max_leaf_nodes=120),\n",
        "                    train_color=\"dodgerblue\",\n",
        "                    test_color=\"tomato\",\n",
        "                    fig=plt.figure(figsize=(9,6))\n",
        "                    )\n",
        "\n",
        "viz.fit(X_train, y_train)\n",
        "viz.score(X_test, y_test)\n",
        "viz.show()"
      ],
      "metadata": {
        "id": "6KghviHnTV02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz = PredictionError(DecisionTreeRegressor(criterion='squared_error', max_depth=10, max_leaf_nodes=120),\n",
        "                      fig=plt.figure(figsize=(6,6))\n",
        "                      )\n",
        "\n",
        "viz.fit(X_train, y_train)\n",
        "viz.score(X_test, y_test)\n",
        "viz.show()"
      ],
      "metadata": {
        "id": "sb6LAb9fT7Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict1={'Model':'Decision Tree Regression ',\n",
        "       'MAE':round((MAEdt),3),\n",
        "       'MSE':round((MSEdt),3),\n",
        "       'R2_score':round((r2dt),3),\n",
        "}\n",
        "training_df=training_df.append(dict1,ignore_index=True)\n",
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2 = {'Model':'Decision Tree Regression ',\n",
        "       'MAE':round((MAEtestdt),3),\n",
        "       'MSE':round((MSEtestdt),3),\n",
        "       'R2_score':round((r2testdt),3),\n",
        "}\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "_GGeRpnuLokX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_feat_imp(decision_regressor)"
      ],
      "metadata": {
        "id": "aJQpinRJLsNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "8XpAjPgTRCcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "Rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "el04S5kLRKqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the y_train and y-test value:\n",
        "y_pred_train_Rf = Rf.predict(X_train)\n",
        "y_pred_test_Rf = Rf.predict(X_test)"
      ],
      "metadata": {
        "id": "n9orI9y6Rmnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_linear_graph(y_pred_test_Rf , y_test )"
      ],
      "metadata": {
        "id": "cwdxSUKMR0dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for training data:\n",
        "MSEdt = mean_squared_error((y_train), (y_pred_train_Rf))\n",
        "MAEdt = mean_absolute_error(y_train, y_pred_train_Rf)\n",
        "r2dt = r2_score(y_train, y_pred_train_Rf)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for testing data:\n",
        "MSEtestdt = mean_squared_error((y_test), (y_pred_test_Rf))\n",
        "MAEtestdt = mean_absolute_error(y_test, y_pred_test_Rf)\n",
        "r2testdt = r2_score(y_test, y_pred_test_Rf)"
      ],
      "metadata": {
        "id": "9EdV8XCzSFwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Errors:\n",
        "print('Training Errors\\nMSE:', MSEdt , '\\nMAE:' , MAEdt , '\\nR2:',round((r2dt),3))\n",
        "print('\\n\\nTesting Errors\\nMSE:', MSEtestdt , '\\nMAE:' , MAEtestdt , '\\nR2:',round((r2testdt),3))"
      ],
      "metadata": {
        "id": "_CYkI5t9SNgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz = ResidualsPlot(RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "                    train_color=\"dodgerblue\",\n",
        "                    test_color=\"tomato\",\n",
        "                    fig=plt.figure(figsize=(9,6))\n",
        "                    )\n",
        "\n",
        "viz.fit(X_train, y_train)\n",
        "viz.score(X_test, y_test)\n",
        "viz.show()"
      ],
      "metadata": {
        "id": "_MseHdwRSY1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz = PredictionError(RandomForestRegressor(n_estimators=100, random_state=42), train_color=\"dodgerblue\",\n",
        "                      test_color=\"tomato\",\n",
        "                      fig=plt.figure(figsize=(8,6)))\n",
        "viz.fit(X_train, y_train)\n",
        "viz.score(X_test, y_test)\n",
        "viz.show()"
      ],
      "metadata": {
        "id": "yy5Q4QWMSrmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict1={'Model':'RandomForestRegressor ',\n",
        "       'MAE':round((MAEdt),3),\n",
        "       'MSE':round((MSEdt),3),\n",
        "       'R2_score':round((r2dt),3),\n",
        "}\n",
        "training_df=training_df.append(dict1,ignore_index=True)\n",
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2 = {'Model':'RandomForestRegressor ',\n",
        "       'MAE':round((MAEtestdt),3),\n",
        "       'MSE':round((MSEtestdt),3),\n",
        "       'R2_score':round((r2testdt),3),\n",
        "}\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "Xn1LpPAJS07h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_feat_imp(Rf)"
      ],
      "metadata": {
        "id": "VL5e9dt3TCuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning - GradientBoostingRegressor"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_dict = {'n_estimators' : [50,80,100],\n",
        "              'max_depth' : [4,6,8,10],\n",
        "              'min_samples_split' : [50,80,100],\n",
        "              'min_samples_leaf' : [40,50]}\n",
        "gb = GradientBoostingRegressor()\n",
        "# Grid search\n",
        "gb_grid = GridSearchCV(estimator=gb,\n",
        "                       param_grid = param_dict,\n",
        "                       cv = 5, verbose=0)\n",
        "gb_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting Best possible paramteres into model:\n",
        "gb_optimal_model = gb_grid.best_estimator_"
      ],
      "metadata": {
        "id": "b2qW7_FeL2St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on train and test data:\n",
        "y_pred_traingbg = gb_optimal_model.predict(X_train)\n",
        "y_predgbg= gb_optimal_model.predict(X_test)"
      ],
      "metadata": {
        "id": "_4fqw1lsL3Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_linear_graph(y_predgbg , y_test )"
      ],
      "metadata": {
        "id": "eKtFOEW2L7PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for training data :\n",
        "MSEGBG = mean_squared_error((y_train), (y_pred_traingbg))\n",
        "MAEGBG = mean_absolute_error(y_train, y_pred_traingbg)\n",
        "r2GBG = r2_score(y_train, y_pred_traingbg)"
      ],
      "metadata": {
        "id": "1RirFC6sL8LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for testing data :\n",
        "MSEtestGBG = mean_squared_error((y_test), (y_predgbg))\n",
        "MAEtestGBG = mean_absolute_error(y_test, y_predgbg)\n",
        "r2testGBG = r2_score(y_test, y_predgbg)"
      ],
      "metadata": {
        "id": "-fAfFuZpMA2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Errors :\n",
        "print('Training Errors\\nMSE:', MSEGBG , '\\nMAE:' , MAEGBG , '\\nR2:',round((r2GBG),2))\n",
        "print('\\n\\nTesting Errors\\nMSE:', MSEtestGBG , '\\nMAE:' , MAEtestGBG , '\\nR2:',round((r2testGBG),2))"
      ],
      "metadata": {
        "id": "J0MVoZCdMC6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz = ResidualsPlot(GridSearchCV(estimator=gb,\n",
        "                       param_grid = param_dict,\n",
        "                       cv = 5, verbose=0),\n",
        "                    train_color=\"dodgerblue\",\n",
        "                    test_color=\"tomato\",\n",
        "                    fig=plt.figure(figsize=(9,6))\n",
        "                    )\n",
        "\n",
        "viz.fit(X_train, y_train)\n",
        "viz.score(X_test, y_test)\n",
        "viz.show()"
      ],
      "metadata": {
        "id": "ddfM0XIYaliR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz = PredictionError(GridSearchCV(estimator=gb,\n",
        "                       param_grid = param_dict,\n",
        "                       cv = 5, verbose=0),\n",
        "                      fig=plt.figure(figsize=(6,6))\n",
        "                      )\n",
        "\n",
        "viz.fit(X_train, y_train)\n",
        "viz.score(X_test, y_test)\n",
        "viz.show()"
      ],
      "metadata": {
        "id": "1Uv4sSmZW6Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "dict1={'Model':'Gradient Boost with GridSearch ',\n",
        "       'MAE':round((MAEGBG),3),\n",
        "       'MSE':round((MSEGBG),3),\n",
        "       'R2_score':round((r2GBG),3)}\n",
        "       \n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "WivFa4IwMGe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict2={'Model':'Gradient Boost with GridSearch ',\n",
        "       'MAE':round((MAEtestGBG),3),\n",
        "       'MSE':round((MSEtestGBG),3),\n",
        "       'R2_score':round((r2testGBG),3)}\n",
        "      \n",
        "test_df=test_df.append(dict2,ignore_index=True) "
      ],
      "metadata": {
        "id": "6DCSjKUNMHg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_feat_imp(gb_optimal_model)"
      ],
      "metadata": {
        "id": "lpYw12M5Xmd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have used GridSearchCV as we known it is a technique for finding the optimal parameter values from a given set of parameters in a grid. It's essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting the best parameter values, predictions are made."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes we have noted significant improvement."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining Train and Test erros in a single dataframe:\n",
        "matrix = pd.concat([training_df,test_df],keys=['Training set','Test set'], axis =1)"
      ],
      "metadata": {
        "id": "RmTMzxgAL2Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix"
      ],
      "metadata": {
        "id": "3Tgj9YBLNG3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp= test_df[['Model','R2_score']]\n",
        "temp= temp.sort_values(by='R2_score', ascending=True)"
      ],
      "metadata": {
        "id": "fPV4og9mL5j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax=temp.plot(x=\"Model\", y=[\"R2_score\"],color ='violet' ,kind=\"bar\", figsize=(15, 6),path_effects=[path_effects.SimplePatchShadow(),path_effects.Normal()])\n",
        "for bar in ax.patches:\n",
        "    ax.annotate(format(bar.get_height(), '.2f'),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=10, xytext=(0, 8),\n",
        "                   textcoords='offset points')"
      ],
      "metadata": {
        "id": "E8NP_29dL6mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The Best performimg model is Gradient Boost Regressor after doing Grid search  so we use this for final prediction.\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are using shap as the model explainability tool."
      ],
      "metadata": {
        "id": "kl8Nj0edLgHG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNVInnTYMLwk"
      },
      "outputs": [],
      "source": [
        "#creating function for getting shape of JS visualization using shap in notebook environment\n",
        "def get_shap(model):\n",
        "  sns.set_style('darkgrid')\n",
        "  for_instance=2\n",
        "  shap.initjs()                                                                                                            #to get JS visualisation\n",
        "  explainer = shap.TreeExplainer(model)\n",
        "  shap_values = explainer(X_test,check_additivity=False)                                                                   #using explainer.shap_values to get shap values of each feature\n",
        "  return shap.plots.force(shap_values[for_instance],feature_names=X.columns)                                               #getting the names of feature and plotting the same using feature_names from X's features as X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw5lpj8vMnzc"
      },
      "outputs": [],
      "source": [
        "#creatung function to get shap summary\n",
        "def get_shap_summary(model):\n",
        "  model.fit(X_test,y_test)\n",
        "  explainer = shap.TreeExplainer(model)\n",
        "  shap_values=explainer.shap_values(X_test,check_additivity=False)                                                         #using explainer.shap_values to get shap values of each feature\n",
        "  return shap.summary_plot(shap_values, X_test,feature_names=X.columns)                                                    #getting the names of feature and plotting the same using feature_names from X's features as X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys6z64cZMxXb"
      },
      "outputs": [],
      "source": [
        "#creatung function to get shap summary\n",
        "def get_shap_summary2(model):\n",
        "  model.fit(X_test,y_test)\n",
        "  explainer = shap.TreeExplainer(model)\n",
        "  shap_values=explainer.shap_values(X_test,check_additivity=False)                                                         #using explainer.shap_values to get shap values of each feature\n",
        "  return shap.summary_plot(shap_values, X_test, plot_type=\"bar\",feature_names=X.columns)                                   #getting the names of feature and plotting the same"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_shap_summary3(model):\n",
        "  model.fit(X_test,y_test)\n",
        "  explainer = shap.TreeExplainer(model)\n",
        "  shap_values=explainer.shap_values(X_test,check_additivity=False)                                                         #using explainer.shap_values to get shap values of each feature\n",
        "  return shap.summary_plot(shap_values, X_test, link=\"identity\",feature_names=X.columns) "
      ],
      "metadata": {
        "id": "VA_UfjLQcYTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling function to get shap JS visualization:\n",
        "get_shap(gb_grid.best_estimator_)"
      ],
      "metadata": {
        "id": "VnbXXOPVMhbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling functions to get shap summary\n",
        "get_shap_summary(gb_grid.best_estimator_)\n",
        "get_shap_summary2(gb_grid.best_estimator_)"
      ],
      "metadata": {
        "id": "4qhflDVUMjgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Things that we concluded from our EDA**.\n",
        "\n",
        "1. **Bikes are rented more when there is considerably low rainfall** at 1.3mm bike counted was 764 can say no rainfall... and count on that too is 739\n",
        "low is around 12mm to 16mm between 11 to 1. \n",
        "2. Bikes are mostly renetd at 32* which is bascially a normal temeprature and has the highest no.. around 1692.. while the lowest at -15 around 25.  \n",
        "3. **Highest number of bikes were rented during Summer seasons** it was 1034 while least number of bikes were rented during *Winter seasons*. it was 225 and almost evenly in spring and autumn ranging from 730 to 8194.  \n",
        "4. Large no. of bikes are rented when there are **non holiday** it was 715 and very less no. is for holiday which was 499.  \n",
        "5. Bikes are only rented only on functional day. with the count of 729.  \n",
        "6. Bikes rented on saturday was more it was around 719 while it was low on sundays around 667.  \n",
        "7. **Maximum no. of bike rented is in the evening at 6 pm** which was 1502 and the least was in the morining at 4 am around 132. The above graph shows that bike should be more available in the evening as compared to morning.  \n",
        "8. Customers have rented bikes more on friday following as considering weekends the count for friday was around 747 and it was some what same in the wednesday and monday to around 740 and 730 but the least no. of bike rented was on the Sunday 625..  \n",
        "9. we can see that our bikes rented count went on increasing for the month is january from 201. it was in the **peek in the month of june**  which was 1245 and then it saw a sudden downfall around 249 counts in december.    \n",
        "\n",
        "Bikes should be more avaliable while there is less rainfall, bike should be more available in the range of 15* to  32* which is normal temperature so bikes should be more avaliable at that temperature ranges. Bikes should be available more on non holidays as compared to those on holiday. People prefer bikes more in the months of summer and almost equally in the spring and autumn and least in  winter,.. so bikes should be more available in summer season and accordingly in the following season. Bikes should be available almost on functional day and being on the safer end few counts for non functional day, bikes are mostly evenly rented ranging form 600 to 750 which is desent count so accordinly bike should be availabe everyday and count should be around 800 .. as better option, no. of supply of bike should me more in the month of june and gradually follows.\n",
        "\n",
        "**Challenges that we faced**;  \n",
        "\n",
        "Removing outlier.  \n",
        "Checking multicollinearity.  \n",
        "Feature selection.  \n",
        "Hypothesis testing.  \n",
        "Feature Selection\n",
        "\n",
        "We created a new feature weekend.\n",
        "\n",
        "\n",
        "-We Have used splitting ratio of **80:20** as it is consider to be the best ratio for model training i.e 80% for trainig and 20% for testing\n",
        "\n",
        "-The Best performimg model is **GradientBoostRegressor** after doing Grid search  so we use this for final prediction.  \n",
        "\n",
        "-We Used shap as the explainability tool for the above model.\n",
        "\n",
        "-The most important feature in the data comes out to be is **Hour**,.\n",
        "\n",
        "**Over all we can conclude that Bike count should be more on the peak hours which is evening hours**.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFyXCBdrrG3B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}